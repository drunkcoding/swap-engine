service ModelInferenceService {
  // Sends a greeting
  rpc ModelInferenceRPC (InferenceRequest) returns (InferenceResponse) {}
}

message InferenceRequest {
  // The name of the model
  required string model_name = 1;
  // The version of the model
  required string model_version = 2;
  // The name of the input tensorsk
  repeated string input_name = 3;
  // The name of the output tensors
  repeated string output_name = 4;
  // The input tensor data
  repeated TensorProto input_data = 5;
}

message InferenceResponse {
  // The output tensor data
  repeated TensorProto output_data = 1;
}

message TensorProto {
  // The data type
  required DataType dtype = 1;
  // The shape of the tensor
  repeated int64 shape = 2;
  // The tensor data
  required bytes data = 3;
}

message DataType {
  enum Type {
    DT_INVALID = 0;
    DT_FLOAT = 1;
    DT_DOUBLE = 2;
    DT_INT32 = 3;
    DT_UINT8 = 4;
    DT_INT16 = 5;
    DT_INT8 = 6;
    DT_STRING = 7;
    DT_COMPLEX64 = 8;
    DT_INT64 = 9;
    DT_BOOL = 10;
    DT_QINT8 = 11;
    DT_QUINT8 = 12;
    DT_QINT32 = 13;
    DT_BFLOAT16 = 14;
    DT_QINT16 = 15;
    DT_QUINT16 = 16;
    DT_UINT16 = 17;
    DT_COMPLEX128 = 18;
    DT_HALF = 19;
    DT_RESOURCE = 20;
    DT_VARIANT = 21;
    DT_UINT32 = 22;
    DT_UINT64 = 23;
  }
}