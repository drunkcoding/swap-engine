syntax = "proto2";


service ModelInference {
  // Sends a greeting
  rpc InferenceHandle (InferenceRequest) returns (InferenceResponse) {}
}

message InferenceRequest {
  // The name of the model
  required string model_name = 1;
  // The version of the model
  required string model_version = 2;
  // The output tensors data format
  repeated TensorProto output_data = 4;
  // The input tensor data
  repeated TensorProto input_data = 5;

  // The session id of the InferenceRequest
  required string session_id = 10;
}

message InferenceResponse {
  // The output tensor data
  repeated TensorProto output_data = 1;

  // The session id of the InferenceResponse
  required string session_id = 10;
}

message TensorProto {
  // The name of the tensor
  required string name = 1;
  // The data type
  required int32 dtype = 2;
  // The shape of the tensor
  repeated int64 shape = 3;
  // The tensor data, empty on request
  optional bytes data = 5;
}

message DataType {
  enum Type {
    DT_INVALID = 0;
    DT_FLOAT = 1;
    DT_DOUBLE = 2;
    DT_INT32 = 3;
    DT_UINT8 = 4;
    DT_INT16 = 5;
    DT_INT8 = 6;
    DT_COMPLEX64 = 8;
    DT_INT64 = 9;
    DT_BOOL = 10;
    DT_BFLOAT16 = 14;
    DT_UINT16 = 17;
    DT_COMPLEX128 = 18;
    DT_HALF = 19;
    DT_UINT32 = 22;
    DT_UINT64 = 23;
  }
}

